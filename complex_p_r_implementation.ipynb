{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "#random.seed(0) if actively using random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def random_complex_vector(n=1, max_norm=1, fixed_norm=True):\n",
    "    \"\"\"\n",
    "    Returns a complex vector of dimension n x 1 (defaults to 1 x 1).\n",
    "    Complex elements have norm ]0,max_norm] uniformly randomly, or norm max_norm if fixed_norm == True\n",
    "    \"\"\"\n",
    "    ret = np.empty(n,dtype=np.complex_)\n",
    "    for i in range(n):\n",
    "        if fixed_norm:\n",
    "            norm = max_norm*(1-random.random()) #to have ]0,max_norm]\n",
    "        else:\n",
    "            norm = max_norm\n",
    "        ang = 2*np.pi*random.random()\n",
    "        ret[i] = max_norm*np.exp((0+1j)*ang)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def random_complex_vector(n=1, distribution='gaussian', param=1/np.sqrt(2)):\n",
    "    assert distribution in ['gaussian','uniform','fixed_norm'], \\\n",
    "        f\"Parameter distribution can not be {distribution}\"\n",
    "    if distribution=='gaussian':\n",
    "        return np.random.normal(loc=0,scale=param,size=n) + \\\n",
    "            (0+1j)*np.random.normal(loc=0,scale=param,size=n)\n",
    "    else:\n",
    "        ret = np.empty(n,dtype=np.complex_)\n",
    "        for i in range(n):\n",
    "            if distribution=='fixed_norm':\n",
    "                norm = param*(1-random.random()) #to have ]0,param]\n",
    "            elif distribution=='uniform':\n",
    "                norm = param\n",
    "            ang = 2*np.pi*random.random()\n",
    "            ret[i] = norm*np.exp((0+1j)*ang)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_complex_vector(length=1, distribution='gaussian', param=1/np.sqrt(2)):\n",
    "    \"\"\"\n",
    "    Returns a complex vector of dimension length x 1\n",
    "    If distribution=='gaussian', complex elements are as x+iy, with x,y ~N(0,param^2), param is std\n",
    "    If distribution=='uniform', complex elements have norm ]0,param] uniformly randomly, phase ]0,2pi] uniformly randomly\n",
    "    If distribution=='fixed_norm', complex elements have norm param, phase ]0,2pi] uniformly randomly\n",
    "    \n",
    "    Complex standard normal (gaussian) distribution has variance 1/2 over the real and over the imaginary part (total variance 1)\n",
    "    \"\"\"\n",
    "    assert distribution in ['gaussian','uniform','fixed_norm'], \\\n",
    "        f\"Parameter distribution can not be {distribution}\"\n",
    "\n",
    "    if distribution=='gaussian':\n",
    "        return np.random.normal(loc=0,scale=param,size=length) + \\\n",
    "            (0+1j)*np.random.normal(loc=0,scale=param,size=length)\n",
    "    elif distribution=='fixed_norm':\n",
    "        return param*np.exp(2*np.pi*(0+1j)*np.random.random(length))\n",
    "    elif distribution=='uniform':\n",
    "        return param*(1 - np.random.random(length))*np.exp(2*np.pi*(0+1j)*np.random.random(length)) #to have norm in ]0,param]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vec = random_complex_vector(100000,'gaussian',1/np.sqrt(2))\n",
    "plt.hist2d(np.real(vec),np.imag(vec), [200,200])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.var(random_complex_vector(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_w_hat(dim):\n",
    "    \"\"\"\n",
    "    Returns a complex vector of dimension d x 1, the \"teacher\" vector to be found.\n",
    "    Its components are randomly initialized: its norm is in [0,1[, its phase in [0,2pi[.\n",
    "    Its complex norm squared is d (which means its numpy.linalg.norm is the root of d)\n",
    "    \"\"\"\n",
    "    #assert isinstance(dim,int) and dim > 0, f\"Given variable dim should not be {dim}\"\n",
    "    ret = random_complex_vector(dim,'uniform',1)\n",
    "    return np.sqrt(dim)*ret/np.linalg.norm(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d = 102\n",
    "np.linalg.norm(define_w_hat(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_X(n,k,law='gaussian',param=1/np.sqrt(2)):\n",
    "    \"\"\"\n",
    "    Returns a matrix of dimension n x k, that is the data.\n",
    "    If law=='gaussian', its rows are complex standard normally distributed, meaning x+iy with x,y~N(0,1/2)\n",
    "    \"\"\"\n",
    "    mat = np.empty((n,k),dtype=np.complex_)\n",
    "    for i in range(n):\n",
    "        mat[i] = random_complex_vector(k,law)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_y(X,w_hat):\n",
    "    \"\"\"\n",
    "    Returns an array of dimension n x 1, built from the data X and the teacher vector w_hat\n",
    "    It keeps only the modulus of every element, that should be in principle in [0,1]\n",
    "    (but can be bigger if the dimension of w_hat is finite)\n",
    "    \"\"\"\n",
    "    return np.abs(X@w_hat)/np.sqrt(len(w_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\nu(h,h_0) = \\frac{1}{2}(|h|^2-|h_0|^2)^2$\n",
    "Could very simply be optimized in the code by not taking the norm of $h_0$ which will be a positive real number, $y^i$, anyways. Could also be optimized (like its derivative) with $h\\cdot h^*$ rather than np.abs(h)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(h,h_0):\n",
    "    \"\"\"\n",
    "    The cost function \"mu\", comparing |X^i@w| to the value y^i=|X^i@w_hat| it corresponds to, minimized in that value\n",
    "    \"\"\"\n",
    "    return (np.abs(h)**2-np.abs(h_0)**2)**2/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first implement $\\partial_1\\nu(h,h_0) = 2(|h|^2-|h_0|^2)\\cdot h$ (assumes $\\frac{d}{dz} |z|^2 = 2z$)\n",
    "\n",
    "$\\partial_1\\nu(h,h_0) = (|h|^2-|h_0|^2)\\cdot h^*$ would be the Wirtinger derivative (assumes $\\frac{d}{dz} |z|^2 = z^*$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_der_1(h,h_0):\n",
    "    \"\"\"\n",
    "    The derivative of the cost function \"mu\" in its first argument, h\n",
    "    \"\"\"\n",
    "    return 2*(np.abs(h)**2-np.abs(h_0)**2)*h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathcal{L}(\\underline{w}) = \\sum_{i=1}^{N} \\nu(h^i,\\hat{h}^i) \\hspace{1cm} h^i = \\frac{1}{\\sqrt{d}}\\underline{X}^i\\cdot\\underline{w}, \\hspace{5mm} \\hat{h}^i=\\frac{1}{\\sqrt{d}}\\underline{X}^i\\cdot\\underline{\\hat{w}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(w,X,y):\n",
    "    \"\"\"\n",
    "    The loss function to be minimized, y^i can be taken in place of \\hat{h}^i\n",
    "    \"\"\"\n",
    "    return np.sum(cost(X@w/np.sqrt(len(w)),y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\partial_{w^k}\\mathcal{L}(\\underline{w}) = \\partial_{w^k}\\sum_{i=1}^N\\nu(h^i,\\hat{h}^i) = \\sum_{i=1}^N\\partial_1\\nu(h^i,\\hat{h}^i)\\partial_{w^k}h^i = \\sum_{i=1}^N\\partial_1\\nu(h^i,\\hat{h}^i)\\frac{1}{\\sqrt{d}}\\cdot X^i_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_der_wk(w,X,y,k):\n",
    "    \"\"\"\n",
    "    The derivative in w_k of the loss function (k ranging from 0 to d-1)\n",
    "    \"\"\"\n",
    "    return np.sum(cost_der_1(X@w/np.sqrt(len(w)),y))*X[:,k]/np.sqrt(len(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$s^i(t) = \\left\\{ \\begin{array}{ll} 1 \\text{ with probability b} \\\\\n",
    "0 \\text{ with probability 1-b} \\end{array} \\right.$\n",
    "$b \\in ]0,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isinbatch(b=1):\n",
    "    \"\"\"\n",
    "    Gives 1 with a probability b, or 0 otherwise. Defaults to being always 1\n",
    "    Function s^i(t)\n",
    "    \"\"\"\n",
    "    return np.random.choice([1,0],p=[b,1-b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "        & s^i(t=0) = \\left\\{\n",
    "        \\begin{array}{ll}\n",
    "            1 \\text{ with probability } b \\\\\n",
    "            0 \\text{ with probability } 1-b\n",
    "        \\end{array}\n",
    "        \\right.\n",
    "        \\\\\n",
    "        & \\mathbb{P}\\left(s^i(t+\\eta) = 1 | s^i(t) = 0\\right) = \\frac{\\eta}{\\tau} \\\\\n",
    "        & \\mathbb{P}\\left(s^i(t+\\eta) = 0 | s^i(t) = 1\\right) = \\frac{1 - b}{b \\tau}\\eta.\n",
    "    \\end{split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_isinbatch(b,eta,tau,s_last):\n",
    "    \"\"\"\n",
    "    The function s^i when defined iteratively, takes its precedent state into account.\n",
    "    Should NOT be called for t=0, this value should be obtained via isinbatch().\n",
    "    Allows to remove a test for every iteration of this function\n",
    "    \"\"\"\n",
    "    prob_1 = eta/tau*(1-s_last) + (1-(1/b-1)*tau/eta)*s_last\n",
    "    prob_0 = 1-prob_1\n",
    "    return np.random.choice([1,0],p=[prob_1,prob_0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$m(t) = \\frac{1}{d}\\left<\\underline{w}(t),\\underline{\\hat{w}}\\right>_{\\mathbb{C}^n} \\equiv \\frac{1}{d}\\sum_{k=1}^d w^{k}(t)^*\\hat{w}^k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnetization_norm(w,w_hat):\n",
    "    return np.abs(w.T@w_hat/len(w_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\underline{w}(t=0) = \\frac{m_0 \\underline{\\hat{w}} + \\sqrt{d}\\cdot\\underline{z}}{\\left|m_0 \\underline{\\hat{w}} + \\sqrt{d}\\cdot\\underline{z}\\right|}\\sqrt{d}, \\qquad m_0 \\in ]0,1], \\quad \\underline{z}\\in\\mathbb{R}^d$, z components are i.i.d complex normal gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_0(m_0, w_hat):\n",
    "    \"\"\"\n",
    "    The initialization of vector w, \"warm initialization\" to avoid getting stuck in a perpendicular\n",
    "    state to w_hat\n",
    "    \"\"\"\n",
    "    z = random_complex_vector(len(w_hat))\n",
    "    vec = m_0*w_hat+np.sqrt(len(w_hat))*z\n",
    "    return vec/np.abs(vec)*np.sqrt(len(w_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "446b379375ee86a0a64a5cb187db7c950ebcdbeba9d95c421944cc0641344ff7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
